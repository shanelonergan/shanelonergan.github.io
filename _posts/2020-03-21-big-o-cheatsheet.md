---
layout: post
title:  "Big O Cheatsheet?"
date:   2020-3-15
description: 'A quick guide to identifying runtime complexity'
img: rest.jpg
tags: [programming, terminal, bash] # add tag
---
---

Welcome to the Big O cheatsheet! This is meant to be a reference point fo quickly identifying some of the most common runtime complexities. It is generalized, so it is not meant to perfectly classify all complex algorithms, but hopefully it can provide a starting point to jump off from. Without further ado, lets dive in!

## Constant Time: O(n) = 1

In order for an algorithm to be constant time, it must take the same amount of time to run no matter what variables are passed in. Whether the algo is passed an array with 1 item or 100 items, it will take the same time to execute.

## Logarithmic Time: O(n) = log(n)

If doubling the number of elements you pass your algo doesn't double the amount of work it has to do, it is likely logarithmic time. Searching operations can usually be assumed to be Logarithmic if the data collection is *sorted*.

## Linear Time

## Quasilinear Time

## Quadratic Time

## Exponential Time
